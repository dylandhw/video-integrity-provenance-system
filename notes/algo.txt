PHASE 1 — Raw input handling
Step 1: Ingest raw frame data

Accept raw Bayer frames directly from the sensor or raw file

Ensure no demosaic, no denoise, no color correction

Validate:

dimensions

bit depth

CFA pattern

If this step fails, abort early.

Step 2: Normalize raw values

Remove fixed black level offset

Clamp to valid range

Do not apply gamma, tone curves, or white balance

Goal: consistent sensor values across frames.

PHASE 2 — Spatial partitioning
Step 3: Divide frame into a grid
Split the frame into evenly sized rectangular blocks
Choose grid size once and keep it fixed
Store grid coordinates deterministically
This defines your spatial reference system.

Step 4: Separate by CFA channel
Inside each grid cell:
Group pixels by color filter (R, G1, G2, B)
Treat each group independently
Do not merge channels.

PHASE 3 — Noise isolation
Step 5: Remove smooth image content

For each pixel:

Estimate local intensity (small neighborhood)

Subtract it from the pixel value

What remains should be:

mostly noise

small random variations

If this doesn’t look noisy, something went wrong earlier.

Step 6: Filter unusable pixels

Exclude:

saturated pixels

dead pixels

obvious defects

Keep a mask of excluded pixels for later

This avoids polluting your fingerprint.

PHASE 4 — Feature extraction
Step 7: Measure noise behavior per grid cell

For each grid cell and CFA channel:

Measure:

average noise level

spread of noise

asymmetry

extreme values

bit-level bias

These are numbers, not images.

Step 8: Quantize the measurements

Convert floating-point values into small, fixed ranges

Ensure small changes in input don’t flip bits wildly

This makes the system stable and repeatable.

PHASE 5 — Local hashing
Step 9: Create a fingerprint for each grid cell

Combine:

quantized noise stats

CFA identity

row/column location hints

Mix them into a fixed-size value

Each cell now has its own mini-fingerprint.

PHASE 6 — Cross-cell consistency
Step 10: Compare neighboring cells

Look at how noise statistics relate between adjacent cells

Record:

ratios

correlations

continuity

This encodes sensor physics across space.

PHASE 7 — Global aggregation
Step 11: Traverse grid in fixed order

Walk the grid deterministically:

top half left→right

bottom half right→left

Do not change this later

Consistency matters more than cleverness.

Step 12: Fold everything into one frame hash

Start with an empty state

For each grid cell:

mix in its fingerprint

mix in its neighbor relationships

End with a single fixed-size frame hash

This is the sensor provenance hash.

PHASE 8 — Steganographic binding
Step 13: Choose embedding locations

Use the frame hash to seed a PRNG

Select a small number of:

noisy pixels

low-visibility areas

Never embed in smooth regions

This hides your proof where no one looks.

Step 14: Embed the hash

Encode the hash with error correction

Embed bits into least-significant bits

Keep changes below perceptual thresholds

The image should look identical.

PHASE 9 — Video support (if applicable)
Step 15: Chain frames together

Each frame includes:

its own hash

the previous frame’s hash

Store frame index and timing info

This prevents tampering over time.

PHASE 10 — Verification pipeline
Step 16: Re-extract embedded data

Read embedded bits from the image

Correct errors

Recover the stored hash

If this fails, verification stops.

Step 17: Recompute hash from raw data

Repeat the hashing process on the frame

Compare computed hash vs embedded hash

Match → authentic
Mismatch → tampered or synthetic

PHASE 11 — Trust & reporting
Step 18: Report verification result

Output:

pass / fail

confidence score

failure reason (noise destroyed, watermark missing, etc.)

Avoid binary-only answers when possible.
